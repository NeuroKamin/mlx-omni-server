# MLX Omni Server [Kamin]

MLX Omni Server ‚Äî —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –Ω–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ MLX –æ—Ç Apple. –°–µ—Ä–≤–µ—Ä –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ —á–∏–ø—ã Apple Silicon (M-—Å–µ—Ä–∏—è) –∏ —Ä–µ–∞–ª–∏–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ API, –ø–æ–∑–≤–æ–ª—è—è –∏–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏ OpenAI –∏ –∑–∞–ø—É—Å–∫–∞—Ç—å –º–æ–¥–µ–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ.

## –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üöÄ **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ Apple Silicon**: —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ MLX, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è M1/M2/M3/M4
- üîå **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å API OpenAI**: –ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —ç–Ω–¥–ø–æ–π–Ω—Ç–æ–≤
- üéØ **–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ò–ò**:
    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ (TTS –∏ STT)
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    - –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–∏–Ω–≥–æ–≤
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- ‚ö°Ô∏è **–í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: –ª–æ–∫–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è —Å –∞–ø–ø–∞—Ä–∞—Ç–Ω—ã–º —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º
- üîê **–ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å**: –≤—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ
- üõ† **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ SDK**: —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º SDK OpenAI –∏ –¥—Ä—É–≥–∏–º–∏ –∫–ª–∏–µ–Ω—Ç–∞–º–∏
- ‚ôªÔ∏è **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞**: –Ω–µ–Ω—É–∂–Ω—ã–µ –∑–∞–≥—Ä—É–∑–∫–∏ —É–¥–∞–ª—è—é—Ç—Å—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞

## –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —ç–Ω–¥–ø–æ–π–Ω—Ç—ã API

–°–µ—Ä–≤–µ—Ä —Ä–µ–∞–ª–∏–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —ç–Ω–¥–ø–æ–π–Ω—Ç—ã:

- [Chat completions](https://platform.openai.com/docs/api-reference/chat): `/v1/chat/completions`
    - ‚úÖ –ß–∞—Ç—ã
    - ‚úÖ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π
    - ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥
    - ‚úÖ LogProbs
    - üöß Vision
- [Audio](https://platform.openai.com/docs/api-reference/audio)
    - ‚úÖ `/v1/audio/speech` - —Ç–µ–∫—Å—Ç –≤ —Ä–µ—á—å
    - ‚úÖ `/v1/audio/transcriptions` - —Ä–µ—á—å –≤ —Ç–µ–∫—Å—Ç
- [Models](https://platform.openai.com/docs/api-reference/models/list)
    - ‚úÖ `/v1/models` - —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
    - ‚úÖ `/v1/models/{model}` - –ø–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å –º–æ–¥–µ–ª—å
    - ‚úÖ `/v1/models/load` - –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ–Ω–µ
    - ‚úÖ `/v1/models/load/{id}` - —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏
- [Images](https://platform.openai.com/docs/api-reference/images)
    - ‚úÖ `/v1/images/generations` - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- [Embeddings](https://platform.openai.com/docs/api-reference/embeddings)
    - ‚úÖ `/v1/embeddings` - —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤


### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ä–≤–µ—Ä–∞

```bash
# –ó–∞–ø—É—Å–∫ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (port 10240)
mlx-omni-server

# –ò–ª–∏ —É–∫–∞–∂–∏—Ç–µ —Å–≤–æ–π –ø–æ—Ä—Ç
mlx-omni-server --port 8000

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –æ–ø—Ü–∏–∏
mlx-omni-server --help
```

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

`WHISPER_CPP_MAX_WORKERS` –∑–∞–¥–∞–µ—Ç —á–∏—Å–ª–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ø–∏–π whisper.cpp –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –°—Ç–æ–ª—å–∫–æ –∂–µ –º–æ–¥–µ–ª–µ–π –º–æ–∂–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤ –ø–∞–º—è—Ç–∏. –£–≤–µ–ª–∏—á—å—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–∂–∏–¥–∞–µ—Ç–µ –º–Ω–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.

```bash
export WHISPER_CPP_MAX_WORKERS=2  # —Ä–∞–∑—Ä–µ—à–∏—Ç—å –¥–≤–µ –∫–æ–ø–∏–∏ whisper.cpp
```

### –ë–∞–∑–æ–≤–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞

```python
from openai import OpenAI

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É —Å–µ—Ä–≤–µ—Ä—É
client = OpenAI(
    base_url="http://localhost:10240/v1",  # –∞–¥—Ä–µ—Å –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
    api_key="not-needed"                   # –∫–ª—é—á –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
)

# –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –∫ —á–∞—Ç—É
response = client.chat.completions.create(
    model="mlx-community/gemma-3-1b-it-4bit-DWQ",
    messages=[{"role": "user", "content": "Hello, how are you?"}]
)
print(response.choices[0].message.content)
```

## –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

MLX Omni Server –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–≤ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –º–æ–¥–µ–ª—è–º–∏.

### –í–∞—Ä–∏–∞–Ω—Ç—ã –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ API

#### REST API

–ú–æ–∂–Ω–æ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ HTTP:

```bash
# –≠–Ω–¥–ø–æ–π–Ω—Ç –¥–ª—è —á–∞—Ç–∞
curl http://localhost:10240/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/gemma-3-1b-it-4bit-DWQ",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
curl http://localhost:10240/v1/models
```

#### OpenAI SDK

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π Python SDK:

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:10240/v1",  # –∞–¥—Ä–µ—Å –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
    api_key="not-needed"                   # –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–µ –Ω—É–∂–µ–Ω
)
```

–í —Ä–∞–∑–¥–µ–ª–µ FAQ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–±–æ—Ç–µ —á–µ—Ä–µ–∑ TestClient.

### –ü—Ä–∏–º–µ—Ä—ã API

#### –ß–∞—Ç

```python
response = client.chat.completions.create(
    model="mlx-community/Llama-3.2-3B-Instruct-4bit",
    messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hello!"}
    ],
    temperature=0,
    stream=True
)

for chunk in response:
    print(chunk)
    print(chunk.choices[0].delta.content)
    print("****************")
```

<details>
<summary>Curl Example</summary>

```shell
curl http://localhost:10240/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/Llama-3.2-3B-Instruct-4bit",
    "stream": true,
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'
```

</details>

#### –¢–µ–∫—Å—Ç –≤ —Ä–µ—á—å

```python
speech_file_path = "mlx_example.wav"
response = client.audio.speech.create(
  model="lucasnewman/f5-tts-mlx",
  voice="alloy",
  input="MLX project is awsome.",
)
response.stream_to_file(speech_file_path)
```

<details>
<summary>Curl Example</summary>

```shell
curl -X POST "http://localhost:10240/v1/audio/speech" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "lucasnewman/f5-tts-mlx",
    "input": "MLX project is awsome",
    "voice": "alloy"
  }' \
  --output ~/Desktop/mlx.wav
```

</details>

#### –†–µ—á—å –≤ —Ç–µ–∫—Å—Ç

```python
audio_file = open("speech.mp3", "rb")
transcript = client.audio.transcriptions.create(
    model="mlx-community/whisper-large-v3-turbo",
    file=audio_file
)

print(transcript.text)
```

<details>
<summary>Curl Example</summary>

```shell
curl -X POST "http://localhost:10240/v1/audio/transcriptions" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@mlx_example.wav" \
  -F "model=mlx-community/whisper-large-v3-turbo"
```

Response:

```json
{
  "text": " MLX Project is awesome!"
}
```

</details>

##### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ whisper.cpp

–î–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —Å–µ—Ä–≤–µ—Ä –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [whisper.cpp](https://github.com/ggerganov/whisper.cpp).

–°–±–æ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç –∏–∑ –∏—Å—Ö–æ–¥–Ω–∏–∫–æ–≤:

```bash
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp
make
```

–ë–∏–Ω–∞—Ä–Ω–∏–∫ `whisper-cli` –Ω—É–∂–Ω–æ –ø–æ–º–µ—Å—Ç–∏—Ç—å –≤ `whisper.cpp/build/bin` –≤ –∫–æ—Ä–Ω–µ —ç—Ç–æ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è. –ú–æ–¥–µ–ª–∏ `ggml-large-v3.bin` –∏ `ggml-silero-v5.1.2.bin` —Å–ª–µ–¥—É–µ—Ç —Ä–∞–∑–º–µ—Å—Ç–∏—Ç—å –≤ `whisper.cpp/models/`.

–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:

```bash
./models/download-ggml-model.sh large-v3
```

–ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–µ—Ä–≤–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—â–µ—Ç —ç—Ç–æ—Ç –±–∏–Ω–∞—Ä–Ω–∏–∫. –ü—É—Ç–∏ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è:

- `WHISPER_CPP_CLI` ‚Äî –ø—É—Ç—å –∫ `whisper-cli`
- `WHISPER_CPP_MODEL` ‚Äî –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
- `WHISPER_CPP_VAD_MODEL` ‚Äî –º–æ–¥–µ–ª—å VAD
- `WHISPER_CPP_THREADS` ‚Äî —á–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤
- `WHISPER_CPP_MAX_WORKERS` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö –∫–æ–ø–∏–π

`WHISPER_CPP_MAX_WORKERS` —É–ø—Ä–∞–≤–ª—è–µ—Ç —á–∏—Å–ª–æ–º —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ whisper.cpp –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.

#### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

```python
image_response = client.images.generate(
    model="argmaxinc/mlx-FLUX.1-schnell",
    prompt="A serene landscape with mountains and a lake",
    n=1,
    size="512x512"
)
```

<details>
<summary>Curl Example</summary>

```shell
curl http://localhost:10240/v1/images/generations \
  -H "Content-Type: application/json" \
  -d '{
    "model": "argmaxinc/mlx-FLUX.1-schnell",
    "prompt": "A cute baby sea otter",
    "n": 1,
    "size": "1024x1024"
  }'
```

</details>

#### –≠–º–±–µ–¥–¥–∏–Ω–≥–∏

```python
# Generate embedding for a single text
response = client.embeddings.create(
    model="mlx-community/all-MiniLM-L6-v2-4bit", input="I like reading"
)

# Examine the response structure
print(f"Response type: {type(response)}")
print(f"Model used: {response.model}")
print(f"Embedding dimension: {len(response.data[0].embedding)}")
```

<details>
<summary>Curl Example</summary>

```shell
curl http://localhost:10240/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mlx-community/all-MiniLM-L6-v2-4bit",
    "input": ["Hello world!", "Embeddings are useful for semantic search."]
  }'
```

</details>

–î–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –ø–∞–ø–∫–µ [examples](examples).

## FAQ

### –ö–∞–∫ —É–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –º–æ–¥–µ–ª–∏?

MLX Omni Server –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Hugging Face –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π. –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –µ—â–µ –Ω–µ —Å–∫–∞—á–∞–Ω–∞, –æ–Ω–∞ –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ. –û–¥–Ω–∞–∫–æ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è.

- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞—Ä–∞–Ω–µ–µ —Å–∫–∞—á–∏–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Hugging Face
- –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ –ø–µ—Ä–µ–¥–∞–π—Ç–µ –ø—É—Ç—å –≤ `model`

–ó–∞—Ä–∞–Ω–µ–µ —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å –º–æ–∂–Ω–æ —á–µ—Ä–µ–∑ `/v1/models/load`. –û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –æ—Ç—Å–ª–µ–¥–∏—Ç—å —á–µ—Ä–µ–∑ `/v1/models/load/{id}`.

```python
# –ú–æ–¥–µ–ª—å —Å Hugging Face
response = client.chat.completions.create(
    model="mlx-community/gemma-3-1b-it-4bit-DWQ",
    messages=[{"role": "user", "content": "Hello"}]
)

# –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
response = client.chat.completions.create(
    model="/path/to/your/local/model",
    messages=[{"role": "user", "content": "Hello"}]
)
```

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–∏—Å—Ç–µ–º–µ –º–æ–∂–Ω–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∑–∞–ø—Ä–æ—Å–æ–º:

```bash
curl http://localhost:10240/v1/models
```

### –ö–∞–∫ —É–∫–∞–∑–∞—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞?

–ü–µ—Ä–µ–¥–∞–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä `model`:

```python
response = client.chat.completions.create(
    model="mlx-community/gemma-3-1b-it-4bit-DWQ",
    messages=[{"role": "user", "content": "Hello"}]
)
```

### –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TestClient –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏?

–î–∞. TestClient –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ API –±–µ–∑ –∑–∞–ø—É—Å–∫–∞ HTTP-—Å–µ—Ä–≤–µ—Ä–∞, —á—Ç–æ —É–¥–æ–±–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤.

```python
from openai import OpenAI
from fastapi.testclient import TestClient
from mlx_omni_server.main import app

client = OpenAI(
    http_client=TestClient(app)
)

response = client.chat.completions.create(
    model="mlx-community/gemma-3-1b-it-4bit-DWQ",
    messages=[{"role": "user", "content": "Hello"}]
)
```

–≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –ø–æ–ª–µ–∑–µ–Ω –¥–ª—è –º–æ–¥—É–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ –∏ –±—ã—Å—Ç—Ä—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π.

### –ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø–æ—è–≤–ª—è—é—Ç—Å—è –æ—à–∏–±–∫–∏?

- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–æ Mac –Ω–∞ Apple Silicon (M1/M2/M3/M4)
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤–µ—Ä—Å–∏—è Python –Ω–µ –Ω–∏–∂–µ 3.9
- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è mlx-omni-server
- –û–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å –ª–æ–≥–∞–º–∏ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π


## –õ–∏—Ü–µ–Ω–∑–∏—è

–ü—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ –ª–∏—Ü–µ–Ω–∑–∏–∏ MIT ‚Äî —Å–º. [LICENSE](LICENSE).

## –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- –°–æ–∑–¥–∞–Ω–æ —Å [MLX](https://github.com/ml-explore/mlx) –æ—Ç Apple
- –î–∏–∑–∞–π–Ω API –≤–¥–æ—Ö–Ω–æ–≤–ª–µ–Ω [OpenAI](https://openai.com)
- –°–µ—Ä–≤–µ—Ä –±–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ [FastAPI](https://fastapi.tiangolo.com/)
- –ß–∞—Ç –æ—Ç [mlx-lm](https://github.com/ml-explore/mlx-examples/tree/main/llms/mlx_lm)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ [mflux](https://github.com/filipstrand/mflux)
- TTS –ø—Ä–æ–µ–∫—Ç—ã [lucasnewman/f5-tts-mlx](https://github.com/lucasnewman/f5-tts-mlx) –∏ [Blaizzy/mlx-audio](https://github.com/Blaizzy/mlx-audio)
- STT –Ω–∞ –±–∞–∑–µ [mlx-whisper](https://github.com/ml-explore/mlx-examples/blob/main/whisper/README.md)
- –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –æ—Ç [mlx-embeddings](https://github.com/Blaizzy/mlx-embeddings)

## –û—Ç–∫–∞–∑ –æ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º –ø—Ä–æ–¥—É–∫—Ç–æ–º OpenAI –∏–ª–∏ Apple. –≠—Ç–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è API OpenAI –Ω–∞ –±–∞–∑–µ MLX.
